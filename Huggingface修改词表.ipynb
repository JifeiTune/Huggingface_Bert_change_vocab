{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer,BertForPreTraining\n",
    "import torch\n",
    "import json\n",
    "def writeToJsonFile(path: str, obj,indent=2):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(obj, ensure_ascii=False,indent=indent,sort_keys=True))\n",
    "def readFromJsonFile(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.loads(f.read())\n",
    "def saveVocab(path:str,obj,sortVocab=False):\n",
    "    obj=list(obj)\n",
    "    if sortVocab:\n",
    "        obj.sort()\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i in obj:\n",
    "            f.write(i+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "modelPath='../bert/chinese_wobert_plus_L-12_H-768_A-12/'#旧模型目录，包括config、词表、模型文件\n",
    "newModelPath='./new/'#这个目录最初只需放置新的词表，修改后的模型、config文件将保存到此目录\n",
    "bert=BertForPreTraining.from_pretrained(modelPath)\n",
    "bert.eval()\n",
    "oldTk=BertTokenizer.from_pretrained(modelPath)\n",
    "newTk=BertTokenizer.from_pretrained(newModelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### 一、记录找得到的，和找不到只能随机或平均初始化的token，生成新config文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原vocab删除31828个，新vocab增加3696个\n",
      "删除与新增token、新的config已写入路径：./new/\n"
     ]
    }
   ],
   "source": [
    "deled,added=list(oldTk.vocab.keys()-newTk.vocab.keys()),list(newTk.vocab.keys()-oldTk.vocab.keys())\n",
    "deled.sort(),added.sort()\n",
    "#记录新旧vocab的token变化\n",
    "print(f\"原vocab删除{len(deled)}个，新vocab增加{len(added)}个\")\n",
    "saveVocab(newModelPath+'原vocab已删除.json',deled,True)\n",
    "saveVocab(newModelPath+'新vocab已增加.json',added,True)\n",
    "print(f\"删除与新增token、新的config已写入路径：{newModelPath}\",)\n",
    "oldConfig=readFromJsonFile(modelPath+'config.json')\n",
    "oldConfig['vocab_size']=newTk.vocab_size\n",
    "#写入新的config文件，变化的也就vocab大小\n",
    "writeToJsonFile(newModelPath+'config.json',oldConfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二、共有的token直接复制权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "common=oldTk.vocab.keys()&newTk.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#对于旧词表中能找到的，记录下每个key的embedding和mlm bias的权重\n",
    "key2embedding,key2mlmBias=dict(),dict()\n",
    "for key in common:\n",
    "    idx=oldTk.vocab[key]\n",
    "    val=bert.bert.embeddings.word_embeddings.weight.data[idx]\n",
    "    key2embedding[key]=val\n",
    "    val=bert.cls.predictions.decoder.bias.data[idx]\n",
    "    key2mlmBias[key]=val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三、旧词表模型中找不到的token，尝试用旧词表细粒度拆分后取平均权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for key in added:\n",
    "    idx=oldTk.encode(key,add_special_tokens=False)#切分后还找不到的就变成了unk\n",
    "    val=bert.bert.embeddings.word_embeddings.weight.data[idx].mean(dim=0)\n",
    "    key2embedding[key]=val\n",
    "    val=bert.cls.predictions.decoder.bias.data[idx].mean(dim=0)\n",
    "    key2mlmBias[key]=val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四、开始恢复和保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(21868, 768)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#新模型调整下embedding层，mlm层大小\n",
    "bert.resize_token_embeddings(newTk.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#根据dict恢复权重\n",
    "for key in newTk.vocab.keys():\n",
    "    idx=newTk.vocab[key]#找到在新模型里的index\n",
    "    val=key2embedding[key]\n",
    "    bert.bert.embeddings.word_embeddings.weight.data[idx]=val\n",
    "    val=key2mlmBias[key]\n",
    "    bert.cls.predictions.decoder.bias.data[idx]=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#保存新模型\n",
    "torch.save(bert.state_dict(),newModelPath+'pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "source": [
    "### 五、检查权重是否符合预期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "old=torch.load(open(modelPath+'pytorch_model.bin',\"rb\"))\n",
    "new=torch.load(open(newModelPath+'pytorch_model.bin',\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for key in common:\n",
    "    oldIdx=oldTk.vocab[key]\n",
    "    newIdx=newTk.vocab[key]\n",
    "    notEqual=old['bert.embeddings.word_embeddings.weight'][oldIdx]!=new['bert.embeddings.word_embeddings.weight'][newIdx]\n",
    "    assert notEqual.sum().item()==0\n",
    "for key in common:\n",
    "    oldIdx=oldTk.vocab[key]\n",
    "    newIdx=newTk.vocab[key]\n",
    "    notEqual=old['cls.predictions.decoder.bias'][oldIdx]!=new['cls.predictions.decoder.bias'][newIdx]\n",
    "    assert notEqual.sum().item()==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}